"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å AI-–∞–Ω–∞–ª–∏–∑–æ–º.
"""

import asyncio
import json
import random
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
from moviepy.video.io.VideoFileClip import VideoFileClip

from farm_content.core import VideoProcessingError, VideoQuality, get_logger
from .advanced_analyzer import AdvancedVideoAnalyzer
from .viral_generator import ViralContentGenerator
from .visual_effects import VisualEffectsEngine
from .multiplatform import MultiPlatformOptimizer
from .text_elements import TextElementsGenerator
from .trend_analyzer import TrendAnalyzer

logger = get_logger(__name__)


class VideoAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≤–∏–¥–µ–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª—É—á—à–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤."""

    def __init__(self):
        self.logger = get_logger(f"{__name__}.VideoAnalyzer")

    async def analyze_video(self, video_path: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
        try:
            with VideoFileClip(str(video_path)) as video:
                return {
                    "duration": video.duration,
                    "fps": video.fps,
                    "size": video.size,
                    "aspect_ratio": video.w / video.h if video.h > 0 else 1,
                    "has_audio": video.audio is not None,
                    "file_size": video_path.stat().st_size,
                }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ {video_path}: {e}")
            raise VideoProcessingError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ: {e}")

    async def find_best_moments(
        self,
        video_path: Path,
        clips_count: int,
        clip_duration: int,
        method: str = "smart",
    ) -> List[Tuple[float, float]]:
        """–ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏."""
        try:
            with VideoFileClip(str(video_path)) as video:
                duration = video.duration

                if method == "uniform":
                    return self._uniform_distribution(
                        duration, clips_count, clip_duration
                    )
                elif method == "smart":
                    return await self._smart_analysis(video, clips_count, clip_duration)
                elif method == "random":
                    return self._random_selection(duration, clips_count, clip_duration)
                else:
                    return self._uniform_distribution(
                        duration, clips_count, clip_duration
                    )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤: {e}")
            # Fallback –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é
            with VideoFileClip(str(video_path)) as video:
                return self._uniform_distribution(
                    video.duration, clips_count, clip_duration
                )

    def _uniform_distribution(
        self, duration: float, clips_count: int, clip_duration: int
    ) -> List[Tuple[float, float]]:
        """–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∏–ø–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏."""
        if duration < clip_duration:
            return [(0, duration)]

        # –ò—Å–∫–ª—é—á–∞–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10% –≤–∏–¥–µ–æ
        start_offset = duration * 0.1
        end_offset = duration * 0.9
        usable_duration = end_offset - start_offset

        if usable_duration < clip_duration:
            return [(start_offset, start_offset + clip_duration)]

        step = usable_duration / clips_count
        clips = []

        for i in range(clips_count):
            start = start_offset + (i * step)
            end = min(start + clip_duration, duration)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–ª–∏–ø –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π
            if end - start >= clip_duration * 0.8:  # –ú–∏–Ω–∏–º—É–º 80% –æ—Ç –∂–µ–ª–∞–µ–º–æ–π –¥–ª–∏–Ω—ã
                clips.append((start, end))

        return clips

    async def _smart_analysis(
        self, video: VideoFileClip, clips_count: int, clip_duration: int
    ) -> List[Tuple[float, float]]:
        """–£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤."""
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—É–¥–∏–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤
            audio_peaks = await self._analyze_audio_activity(video)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å—Ü–µ–Ω
            scene_changes = await self._detect_scene_changes(video)

            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤
            candidates = self._combine_analysis_data(
                audio_peaks, scene_changes, video.duration
            )

            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –º–æ–º–µ–Ω—Ç—ã
            return self._select_best_clips(candidates, clips_count, clip_duration)

        except Exception as e:
            logger.warning(f"Smart analysis failed, falling back to uniform: {e}")
            return self._uniform_distribution(
                video.duration, clips_count, clip_duration
            )

    async def _analyze_audio_activity(self, video: VideoFileClip) -> List[float]:
        """–ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ."""
        if not video.audio:
            return []

        try:
            # –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ –º–∞—Å—Å–∏–≤
            audio_array = video.audio.to_soundarray()

            # –í—ã—á–∏—Å–ª—è–µ–º RMS —ç–Ω–µ—Ä–≥–∏—é –¥–ª—è –∫–∞–∂–¥–æ–π —Å–µ–∫—É–Ω–¥—ã
            chunk_size = int(video.audio.fps)  # 1 —Å–µ–∫—É–Ω–¥–∞

            energy_levels = []
            for i in range(0, len(audio_array), chunk_size):
                chunk = audio_array[i : i + chunk_size]
                if len(chunk) > 0:
                    # RMS —ç–Ω–µ—Ä–≥–∏—è
                    rms = np.sqrt(np.mean(chunk**2))
                    energy_levels.append(rms)

            return energy_levels

        except Exception as e:
            logger.warning(f"Audio analysis failed: {e}")
            return []

    async def _detect_scene_changes(self, video: VideoFileClip) -> List[float]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–º–µ–Ω—ã —Å—Ü–µ–Ω."""
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
            scene_changes = []
            prev_frame = None

            for t in range(0, int(video.duration), 5):  # –ö–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                try:
                    frame = video.get_frame(t)

                    if prev_frame is not None:
                        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏
                        diff = np.mean(
                            np.abs(frame.astype(float) - prev_frame.astype(float))
                        )
                        scene_changes.append((t, diff))

                    prev_frame = frame

                except Exception:
                    continue

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            scene_changes.sort(key=lambda x: x[1], reverse=True)

            return [t for t, _ in scene_changes[:20]]  # –¢–æ–ø 20 –∏–∑–º–µ–Ω–µ–Ω–∏–π

        except Exception as e:
            logger.warning(f"Scene change detection failed: {e}")
            return []

    def _combine_analysis_data(
        self, audio_peaks: List[float], scene_changes: List[float], duration: float
    ) -> List[Tuple[float, float]]:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞."""
        candidates = []

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—É–¥–∏–æ –ø–∏–∫–æ–≤
        if audio_peaks:
            avg_energy = np.mean(audio_peaks)
            for i, energy in enumerate(audio_peaks):
                if energy > avg_energy * 1.2:  # 20% –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
                    candidates.append((i, energy * 0.7))  # –í–µ—Å 0.7

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–º–µ–Ω—ã —Å—Ü–µ–Ω
        for t in scene_changes:
            candidates.append((t, 0.8))  # –í–µ—Å 0.8

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –∫–∞–∫ fallback
        for i in range(int(duration * 0.1), int(duration * 0.9), 30):
            candidates.append((i, 0.3))  # –ù–∏–∑–∫–∏–π –≤–µ—Å

        return candidates

    def _select_best_clips(
        self,
        candidates: List[Tuple[float, float]],
        clips_count: int,
        clip_duration: int,
    ) -> List[Tuple[float, float]]:
        """–í—ã–±–æ—Ä –ª—É—á—à–∏—Ö –∫–ª–∏–ø–æ–≤ –∏–∑ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤."""
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–µ—Å—É
        candidates.sort(key=lambda x: x[1], reverse=True)

        selected_clips = []
        used_intervals = []

        for start_time, weight in candidates:
            if len(selected_clips) >= clips_count:
                break

            end_time = start_time + clip_duration

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∫–ª–∏–ø–∞–º–∏
            overlaps = False
            for used_start, used_end in used_intervals:
                if not (end_time <= used_start or start_time >= used_end):
                    overlaps = True
                    break

            if not overlaps:
                selected_clips.append((start_time, end_time))
                used_intervals.append((start_time, end_time))

        return selected_clips

    def _random_selection(
        self, duration: float, clips_count: int, clip_duration: int
    ) -> List[Tuple[float, float]]:
        """–°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–º–µ–Ω—Ç–æ–≤."""
        import random

        if duration < clip_duration:
            return [(0, duration)]

        # –ò—Å–∫–ª—é—á–∞–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10%
        start_offset = duration * 0.1
        end_offset = duration * 0.9 - clip_duration

        if end_offset <= start_offset:
            return [(start_offset, start_offset + clip_duration)]

        clips = []
        attempts = 0
        max_attempts = clips_count * 10

        while len(clips) < clips_count and attempts < max_attempts:
            start = random.uniform(start_offset, end_offset)
            end = start + clip_duration

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
            overlaps = any(
                not (end <= existing_start or start >= existing_end)
                for existing_start, existing_end in clips
            )

            if not overlaps:
                clips.append((start, end))

            attempts += 1

        return clips


class ViralClipExtractor:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∫–ª–∏–ø–æ–≤ —Å AI-–∞–Ω–∞–ª–∏–∑–æ–º –∏ –≤–∏—Ä—É—Å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π."""

    def __init__(self):
        self.logger = get_logger(f"{__name__}.ViralClipExtractor")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.analyzer = AdvancedVideoAnalyzer()
        self.generator = ViralContentGenerator()
        self.effects_engine = VisualEffectsEngine()
        self.platform_optimizer = MultiPlatformOptimizer()
        self.text_generator = TextElementsGenerator()
        self.trend_analyzer = TrendAnalyzer()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.quality_settings = {
            VideoQuality.LOW: {"height": 480, "bitrate": "1000k"},
            VideoQuality.MEDIUM: {"height": 720, "bitrate": "2500k"},
            VideoQuality.HIGH: {"height": 1080, "bitrate": "5000k"},
            VideoQuality.ULTRA: {"height": 2160, "bitrate": "15000k"},
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≤–∏—Ä—É—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        self.viral_settings = {
            "min_energy_threshold": 0.6,
            "optimal_clip_duration": 30,
            "max_clips_per_video": 5,
            "auto_enhance": True,
            "generate_metadata": True,
            "multiplatform_export": True
        }

    async def create_viral_clips(
        self,
        video_path: Path,
        target_platforms: List[str] = ["tiktok", "instagram_reels", "youtube_shorts"],
        auto_detect_best_moments: bool = True,
        apply_viral_effects: bool = True,
        generate_metadata: bool = True,
        output_dir: Optional[Path] = None,
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—É—Å–Ω—ã—Ö –∫–ª–∏–ø–æ–≤ —Å –ø–æ–ª–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π."""
        
        self.logger.info(f"üî• –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—É—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ {video_path}")
        
        try:
            if output_dir is None:
                output_dir = video_path.parent / "viral_content"
                output_dir.mkdir(exist_ok=True)

            # 1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ
            self.logger.info("üìä –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ...")
            analysis = await self.analyzer.analyze_viral_potential(video_path)
            
            viral_score = analysis.get("viral_score", 0.5)
            self.logger.info(f"üéØ –í–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: {viral_score:.2f}")
            
            # 2. –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º
            self.logger.info("üöÄ –°–æ–∑–¥–∞–Ω–∏–µ –º—É–ª—å—Ç–∏–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
            platform_content = await self.platform_optimizer.create_optimized_content(
                video_path=video_path,
                target_platforms=target_platforms,
                content_strategy="viral_focused",
                auto_detect_best_moments=auto_detect_best_moments,
                generate_variations=True
            )
            
            # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            metadata_results = {}
            if generate_metadata:
                self.logger.info("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
                for platform in target_platforms:
                    metadata = self.generator.generate_viral_metadata(
                        analysis, platform=platform
                    )
                    metadata_results[platform] = metadata
            
            # 4. –°–æ–∑–¥–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–π
            self.logger.info("üìÖ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π...")
            posting_schedule = await self.platform_optimizer.generate_posting_schedule(
                platform_content, strategy="maximum_reach"
            )
            
            # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = {
                "source_video": str(video_path),
                "analysis": analysis,
                "platform_content": platform_content,
                "metadata": metadata_results,
                "posting_schedule": posting_schedule,
                "summary": {
                    "total_clips_created": sum(
                        len(data.get("main_versions", [])) for data in platform_content.values()
                    ),
                    "total_variations": sum(
                        len(data.get("variations", [])) for data in platform_content.values()
                    ),
                    "platforms_optimized": len(target_platforms),
                    "viral_score": viral_score,
                    "processing_time": "calculated_later"
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ JSON
            import json
            metadata_file = output_dir / f"{video_path.stem}_viral_content.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"‚úÖ –í–∏—Ä—É—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω! –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata_file}")
            return results

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏—Ä—É—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            raise VideoProcessingError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–∏—Ä—É—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {e}")

    async def extract_clip(
        self,
        video_path: Path,
        start_time: float,
        end_time: float,
        output_quality: VideoQuality = VideoQuality.MEDIUM,
        mobile_format: bool = True,
        normalize_audio: bool = True,
        output_dir: Optional[Path] = None,
        apply_effects: bool = False,
        target_platform: str = "tiktok",
    ) -> Path:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª–∏–ø–∞ –∏–∑ –≤–∏–¥–µ–æ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏."""
        try:
            if output_dir is None:
                output_dir = video_path.parent / "clips"
                output_dir.mkdir(exist_ok=True)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            timestamp = f"{int(start_time)}-{int(end_time)}"
            platform_suffix = f"_{target_platform}" if apply_effects else ""
            output_file = output_dir / f"{video_path.stem}_clip_{timestamp}{platform_suffix}.mp4"

            with VideoFileClip(str(video_path)) as video:
                # –û–±—Ä–µ–∑–∞–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                clip = video.subclip(start_time, end_time)

                # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if apply_effects:
                    self.logger.info(f"üé® –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –¥–ª—è {target_platform}...")
                    enhanced_clip = await self.effects_engine.apply_viral_effects(
                        video_path,
                        style="tiktok_viral",
                        intensity=0.8,
                        auto_optimize=True,
                        target_platform=target_platform
                    )
                    clip = enhanced_clip.subclip(start_time, end_time)

                # –ü—Ä–∏–º–µ–Ω—è–µ–º –±–∞–∑–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                if mobile_format:
                    clip = self._apply_mobile_format(clip)

                clip = self._apply_quality_settings(clip, output_quality)

                if normalize_audio and clip.audio:
                    clip = clip.audio_normalize()

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: clip.write_videofile(
                        str(output_file),
                        codec="libx264",
                        audio_codec="aac",
                        temp_audiofile="temp-audio.m4a",
                        remove_temp=True,
                        verbose=False,
                        logger=None,
                    ),
                )

            logger.info(f"‚úÖ –ö–ª–∏–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            return output_file

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª–∏–ø–∞: {e}")
            raise VideoProcessingError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–ª–∏–ø: {e}")

    async def analyze_and_extract_best_clips(
        self,
        video_path: Path,
        clips_count: int = 3,
        target_duration: int = 30,
        min_viral_score: float = 0.6,
        output_dir: Optional[Path] = None,
    ) -> List[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –∫–ª–∏–ø–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ AI."""
        
        self.logger.info(f"üéØ –ü–æ–∏—Å–∫ {clips_count} –ª—É—á—à–∏—Ö –∫–ª–∏–ø–æ–≤ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é {target_duration}—Å")
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ
            analysis = await self.analyzer.analyze_viral_potential(video_path)
            
            # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∫–ª–∏–ø—ã
            optimal_clips = await self.analyzer.find_optimal_clips(
                video_path,
                target_duration=target_duration,
                clips_count=clips_count * 2,  # –ë–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞
                content_type="auto"
            )
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤–∏—Ä—É—Å–Ω–æ–º—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É
            filtered_clips = [
                clip for clip in optimal_clips
                if clip[2].get("viral_potential", 0) >= min_viral_score
            ]
            
            # –ë–µ—Ä–µ–º —Ç–æ–ø –∫–ª–∏–ø–æ–≤
            best_clips = sorted(
                filtered_clips,
                key=lambda x: x[2].get("viral_potential", 0),
                reverse=True
            )[:clips_count]
            
            # –ï—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∏—Ö –∫–ª–∏–ø–æ–≤, –±–µ—Ä–µ–º –ª—É—á—à–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ
            if len(best_clips) < clips_count:
                remaining = clips_count - len(best_clips)
                additional_clips = sorted(
                    optimal_clips,
                    key=lambda x: x[2].get("energy", 0),
                    reverse=True
                )[:remaining]
                best_clips.extend(additional_clips)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∏–ø—ã
            results = []
            for i, (start, end, clip_info) in enumerate(best_clips):
                self.logger.info(f"üé¨ –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–∞ {i+1}/{len(best_clips)}: {start:.1f}s - {end:.1f}s")
                
                clip_path = await self.extract_clip(
                    video_path=video_path,
                    start_time=start,
                    end_time=end,
                    output_dir=output_dir,
                    apply_effects=True,
                    target_platform="tiktok"
                )
                
                clip_result = {
                    "clip_index": i + 1,
                    "file_path": str(clip_path),
                    "start_time": start,
                    "end_time": end,
                    "duration": end - start,
                    "viral_potential": clip_info.get("viral_potential", 0),
                    "energy_level": clip_info.get("energy", 0),
                    "motion_level": clip_info.get("motion", 0),
                    "audio_level": clip_info.get("audio", 0),
                }
                
                results.append(clip_result)
            
            self.logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(results)} –∫–ª–∏–ø–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º –≤–∏—Ä—É—Å–Ω—ã–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª–∏–ø–æ–≤: {e}")
            raise VideoProcessingError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –∏–∑–≤–ª–µ—á—å –∫–ª–∏–ø—ã: {e}")

    def _apply_mobile_format(self, clip: VideoFileClip) -> VideoFileClip:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (9:16)."""
        try:
            w, h = clip.size

            # –ï—Å–ª–∏ —É–∂–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            if h > w:
                return clip

            # –î–µ–ª–∞–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–º (crop –ø–æ —Ü–µ–Ω—Ç—Ä—É)
            target_w = int(h * 9 / 16)

            if target_w <= w:
                # –û–±—Ä–µ–∑–∞–µ–º –ø–æ —à–∏—Ä–∏–Ω–µ
                x_center = w // 2
                x1 = x_center - target_w // 2
                x2 = x1 + target_w
                clip = clip.crop(x1=x1, x2=x2)
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º —á–µ—Ä–Ω—ã–µ –ø–æ–ª–æ—Å—ã –∏–ª–∏ –∏–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
                clip = clip.resize(height=h)

            return clip

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")
            return clip

    async def create_perfect_viral_content(
        self,
        video_path: Path,
        target_platforms: List[str] = ["tiktok", "instagram_reels", "youtube_shorts"],
        use_trend_analysis: bool = True,
        add_text_overlays: bool = True,
        intensity: float = 0.9,
        output_dir: Optional[Path] = None,
    ) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –≤–∏—Ä—É—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö AI-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.
        
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã:
        - –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        - AI-–∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ 
        - –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ —Ç—Ä–µ–Ω–¥—ã
        - –í–∏—Ä—É—Å–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã
        - –¢–µ–∫—Å—Ç–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã 
        - –ú—É–ª—å—Ç–∏–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        """
        
        self.logger.info("üöÄ –°–æ–∑–¥–∞–µ–º –ò–î–ï–ê–õ–¨–ù–´–ô –≤–∏—Ä—É—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç!")
        self.logger.info(f"üì± –¶–µ–ª–µ–≤—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã: {', '.join(target_platforms)}")
        self.logger.info(f"üéØ –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å: {intensity:.1f}")
        
        start_time = asyncio.get_event_loop().time()
        
        try:
            if output_dir is None:
                output_dir = video_path.parent / "perfect_viral_content" 
            output_dir.mkdir(exist_ok=True)
            
            # =================== –®–ê–ì 1: –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–û–í ===================
            trends_analysis = {}
            if use_trend_analysis:
                self.logger.info("üîç –®–∞–≥ 1/6: –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤...")
                trends_analysis = await self.trend_analyzer.analyze_current_trends(target_platforms)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –ø–æ —Ç—Ä–µ–Ω–¥–∞–º
                trends_report_path = output_dir / f"trends_report_{video_path.stem}.json"
                self.trend_analyzer.export_trends_report(trends_analysis, trends_report_path)
            
            # =================== –®–ê–ì 2: AI-–ê–ù–ê–õ–ò–ó –í–ò–î–ï–û ===================
            self.logger.info("üß† –®–∞–≥ 2/6: –ì–ª—É–±–æ–∫–∏–π AI-–∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ...")
            video_analysis = await self.analyzer.analyze_viral_potential(video_path)
            viral_score = video_analysis.get("viral_score", 0.5)
            
            self.logger.info(f"üìä –ë–∞–∑–æ–≤—ã–π –≤–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: {viral_score:.2f}")
            
            # =================== –®–ê–ì 3: –ê–î–ê–ü–¢–ê–¶–ò–Ø –ü–û–î –¢–†–ï–ù–î–´ ===================
            adaptation_plans = {}
            if use_trend_analysis and trends_analysis:
                self.logger.info("üéØ –®–∞–≥ 3/6: –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ–¥ —Ç—Ä–µ–Ω–¥—ã...")
                
                for platform in target_platforms:
                    adaptation_plan = await self.trend_analyzer.adapt_content_to_trends(
                        video_analysis, trends_analysis, platform
                    )
                    adaptation_plans[platform] = adaptation_plan
                    
                    improvement = adaptation_plan.get("estimated_improvement", 0)
                    self.logger.info(f"üìà {platform}: –æ–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ +{improvement:.1%}")
            
            # =================== –®–ê–ì 4: –°–û–ó–î–ê–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –ö–û–ù–¢–ï–ù–¢–ê ===================
            self.logger.info("üé¨ –®–∞–≥ 4/6: –°–æ–∑–¥–∞–Ω–∏–µ –º—É–ª—å—Ç–∏–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
            
            platform_content = await self.platform_optimizer.create_optimized_content(
                video_path=video_path,
                target_platforms=target_platforms,
                content_strategy="maximum_viral",
                auto_detect_best_moments=True,
                generate_variations=True,
                viral_intensity=intensity
            )
            
            # =================== –®–ê–ì 5: –î–û–ë–ê–í–õ–ï–ù–ò–ï –¢–ï–ö–°–¢–û–í–´–• –≠–õ–ï–ú–ï–ù–¢–û–í ===================
            enhanced_content = {}
            if add_text_overlays:
                self.logger.info("üìù –®–∞–≥ 5/6: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∏—Ä—É—Å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤...")
                
                for platform, content_data in platform_content.items():
                    enhanced_content[platform] = content_data.copy()
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç—ã –∫ –æ—Å–Ω–æ–≤–Ω—ã–º –≤–µ—Ä—Å–∏—è–º
                    if "main_versions" in content_data:
                        for i, video_file in enumerate(content_data["main_versions"]):
                            if Path(video_file).exists():
                                enhanced_video = await self.text_generator.add_viral_text_overlays(
                                    Path(video_file),
                                    platform=platform,
                                    auto_generate_text=True,
                                    viral_intensity=intensity
                                )
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                                enhanced_path = output_dir / f"{platform}_with_text_{i}.mp4"
                                await asyncio.get_event_loop().run_in_executor(
                                    None,
                                    lambda: enhanced_video.write_videofile(
                                        str(enhanced_path), 
                                        codec="libx264", 
                                        audio_codec="aac",
                                        verbose=False,
                                        logger=None
                                    )
                                )
                                
                                enhanced_content[platform].setdefault("enhanced_versions", []).append(str(enhanced_path))
                                enhanced_video.close()
            else:
                enhanced_content = platform_content
            
            # =================== –®–ê–ì 6: –§–ò–ù–ê–õ–¨–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –ú–ï–¢–ê–î–ê–ù–ù–´–• ===================
            self.logger.info("üìã –®–∞–≥ 6/6: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
            
            final_metadata = {}
            for platform in target_platforms:
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –µ—Å–ª–∏ –µ—Å—Ç—å
                analysis_for_metadata = video_analysis
                if platform in adaptation_plans:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏—è–º–∏
                    adaptation = adaptation_plans[platform]
                    analysis_for_metadata = {
                        **video_analysis,
                        "adapted_for_trends": True,
                        "trend_adaptations": adaptation,
                        "estimated_viral_boost": adaptation.get("estimated_improvement", 0)
                    }
                
                metadata = self.generator.generate_viral_metadata(
                    analysis_for_metadata,
                    platform=platform,
                    intensity=intensity
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                if platform in adaptation_plans:
                    content_mods = adaptation_plans[platform].get("content_modifications", {})
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ö–µ—à—Ç–µ–≥–∏ —Ç—Ä–µ–Ω–¥–æ–≤—ã–º–∏
                    if content_mods.get("hashtag_suggestions"):
                        trending_hashtags = content_mods["hashtag_suggestions"]
                        existing_hashtags = metadata.get("hashtags", [])
                        # –°–º–µ—à–∏–≤–∞–µ–º —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ –∏ AI-—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ö–µ—à—Ç–µ–≥–∏
                        metadata["hashtags"] = trending_hashtags[:3] + existing_hashtags[:7]
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ–Ω–¥–æ–≤—ã–π call-to-action
                    if content_mods.get("call_to_action"):
                        metadata["call_to_action"] = content_mods["call_to_action"]
                
                final_metadata[platform] = metadata
            
            # =================== –°–û–ó–î–ê–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ì–û –û–¢–ß–ï–¢–ê ===================
            processing_time = asyncio.get_event_loop().time() - start_time
            
            final_results = {
                "source_video": str(video_path),
                "created_at": str(datetime.now()),
                "processing_time_seconds": round(processing_time, 2),
                
                # –ê–Ω–∞–ª–∏–∑
                "original_analysis": video_analysis,
                "trends_analysis": trends_analysis,
                "trend_adaptations": adaptation_plans,
                
                # –ö–æ–Ω—Ç–µ–Ω—Ç
                "platform_content": enhanced_content,
                "final_metadata": final_metadata,
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                "performance_metrics": {
                    "original_viral_score": viral_score,
                    "estimated_improvements": {
                        platform: adaptation_plans.get(platform, {}).get("estimated_improvement", 0)
                        for platform in target_platforms
                    },
                    "total_content_pieces": sum(
                        len(data.get("enhanced_versions", data.get("main_versions", [])))
                        for data in enhanced_content.values()
                    ),
                    "platforms_optimized": len(target_platforms),
                    "ai_systems_used": [
                        "AdvancedVideoAnalyzer",
                        "TrendAnalyzer", 
                        "ViralContentGenerator",
                        "VisualEffectsEngine",
                        "MultiPlatformOptimizer",
                        "TextElementsGenerator"
                    ]
                },
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                "publishing_strategy": await self._create_publishing_strategy(
                    enhanced_content, final_metadata, trends_analysis
                )
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
            final_report_path = output_dir / f"PERFECT_VIRAL_CONTENT_{video_path.stem}.json"
            with open(final_report_path, 'w', encoding='utf-8') as f:
                json.dump(final_results, f, ensure_ascii=False, indent=2)
            
            self.logger.info("=" * 60)
            self.logger.info("üéâ –ò–î–ï–ê–õ–¨–ù–´–ô –í–ò–†–£–°–ù–´–ô –ö–û–ù–¢–ï–ù–¢ –°–û–ó–î–ê–ù!")
            self.logger.info(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.1f} —Å–µ–∫")
            self.logger.info(f"üé¨ –°–æ–∑–¥–∞–Ω–æ –≤–∏–¥–µ–æ: {final_results['performance_metrics']['total_content_pieces']}")
            self.logger.info(f"üì± –ü–ª–∞—Ç—Ñ–æ—Ä–º—ã: {len(target_platforms)}")
            self.logger.info(f"üìà –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏—Ä–æ—Å—Ç: {sum(final_results['performance_metrics']['estimated_improvements'].values()) / len(target_platforms):.1%}")
            self.logger.info(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {final_report_path}")
            self.logger.info("=" * 60)
            
            return final_results
            
        except Exception as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê —Å–æ–∑–¥–∞–Ω–∏—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            raise VideoProcessingError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–π –≤–∏—Ä—É—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {e}")

    async def _create_publishing_strategy(
        self,
        content: Dict[str, Any],
        metadata: Dict[str, Any],
        trends: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏."""
        
        from datetime import datetime, timedelta
        
        strategy = {
            "optimal_posting_times": {
                "tiktok": ["18:00", "20:00", "22:00"],
                "instagram_reels": ["19:00", "21:00"], 
                "youtube_shorts": ["20:00", "22:00"]
            },
            "publishing_sequence": [],
            "cross_promotion_plan": {},
            "performance_tracking": {}
        }
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        base_time = datetime.now()
        
        for i, (platform, content_data) in enumerate(content.items()):
            versions = content_data.get("enhanced_versions", content_data.get("main_versions", []))
            
            for j, version_path in enumerate(versions):
                publish_time = base_time + timedelta(hours=i*2, minutes=j*30)
                
                strategy["publishing_sequence"].append({
                    "platform": platform,
                    "content_file": version_path,
                    "scheduled_time": publish_time.isoformat(),
                    "metadata": metadata.get(platform, {}),
                    "expected_performance": "high" if platform in ["tiktok", "instagram_reels"] else "medium"
                })
        
        return strategy

    def _apply_quality_settings(
        self, clip: VideoFileClip, quality: VideoQuality
    ) -> VideoFileClip:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–∞—á–µ—Å—Ç–≤–∞."""
        try:
            settings = self.quality_settings.get(quality)
            if not settings:
                return clip

            target_height = settings["height"]

            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if clip.h > target_height:
                clip = clip.resize(height=target_height)

            return clip

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
            return clip
